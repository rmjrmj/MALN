# MALN

The project contains the source code of the TCSVT submitted paper "MALN: Multimodal adversarial learning network for conversational emotion recognition". The paper introduces a novel architecture for emotional recognition in conversation.

Since the manuscript is still in the review stage, we only provide the main part of the model (including the model architecture and the training, evaluation process). After the paper is accepted, we will reorganize and open source all the codes in this project.

Training and Evaluation
1. Download data features (IEMOCAP and MELD) from the link: https://github.com/declare-lab/conv-emotion and save the dialogue features to the folder "Features"
2. Run "python train_MALN.py"

Models and generated features will be saved after the training process.

Citation
After the paper is accepted, we will add the citation information.
